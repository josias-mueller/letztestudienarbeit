{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "import matplotlib.colors as col\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"../result/\"\n",
    "outdir = \"target/\"\n",
    "\n",
    "def ensure_exists(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "too_big_for_rstar = [\n",
    "    \"synthetic_180x90x256_BigElement\",\n",
    "    \"synthetic_180x90x256_VeryBigElement\",\n",
    "    \"synthetic_180x90x64_VeryVeryBigElement\",\n",
    "    \"synthetic_180x90x256_VeryVeryBigElement\",\n",
    "]\n",
    "\n",
    "sizes = [16_200, 44_692, 64_800, 140_974, 259_200, 1_036_800, 3_808_651, 4_147_200]\n",
    "itersz = [0, *sizes[:], 5_000_000]\n",
    "\n",
    "ranges = []\n",
    "for previous, current in zip(itersz, itersz[1:]):\n",
    "    ranges.append((previous, current))\n",
    "def rangeindex(number):\n",
    "    for ((cur, next), i) in zip(ranges, range(len(ranges))):\n",
    "        if number > cur and number <= next:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "env_sizes = [16, 64, 256, 1024, 4096]\n",
    "env_count = 16\n",
    "\n",
    "nelements = {\n",
    "    \"matthe\": 3_808_651,\n",
    "    \"open\": 140_974,\n",
    "    \"simple\": 44_692,\n",
    "    \"180x90x256\": 4_147_200,\n",
    "    \"180x90x64\": 1_036_800,\n",
    "    \"180x90x16\": 259_200,\n",
    "    \"180x90x4\": 64_800,\n",
    "    \"180x90x1\": 16_200,\n",
    "}\n",
    "\n",
    "types = {\n",
    "    \"VeryVeryBigElement\": 1024,\n",
    "    \"VeryBigElement\": 512,\n",
    "    \"BiggerElement\": 24,\n",
    "    \"BigElement\": 256,\n",
    "    \"Element\": 12,\n",
    "}\n",
    "\n",
    "def typename_by_mult(mult):\n",
    "    for (tn, tsz) in types.items():\n",
    "        if tsz == mult:\n",
    "            return tn\n",
    "    return None\n",
    "\n",
    "hprcol = col.get_named_colors_mapping().get(\"green\")\n",
    "rstcol = col.get_named_colors_mapping().get(\"orange\")\n",
    "\n",
    "hprlab = \"HPRTree\"\n",
    "rstlab = \"R*Tree\"\n",
    "\n",
    "imgext = \".svg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcount(datasetname: str):\n",
    "    count = None\n",
    "    for (k, v) in nelements.items():\n",
    "        if datasetname.count(k) != 0:\n",
    "            count = v\n",
    "            break\n",
    "    if count == None:\n",
    "        if datasetname.find(\"clustered\") != -1:\n",
    "            startidx = datasetname.index(\"clustered\") + len(\"clustered_\")\n",
    "            endidx = datasetname.rfind(\"_\")-6\n",
    "            nums = datasetname[startidx:endidx].split(\"_\")\n",
    "            count = int(nums[0])*int(nums[1])\n",
    "        elif datasetname.find(\"uniform\") != -1:\n",
    "            startidx = datasetname.index(\"uniform\") + len(\"uniform_\")\n",
    "            endidx = datasetname.rfind(\"_\")-2\n",
    "            count = int(datasetname[startidx:endidx])\n",
    "    assert count != None, \"could not recognize dataset\"\n",
    "    return count\n",
    "\n",
    "def gettypemult(datasetname: str):\n",
    "    sizemult = None\n",
    "    for (k, v) in types.items():\n",
    "        if datasetname.count(k) != 0:\n",
    "            sizemult = v\n",
    "            break\n",
    "    assert sizemult != None, \"could not recognize type\"\n",
    "    return sizemult\n",
    "\n",
    "def theoreticalmin(datasetname: str):\n",
    "    base = getcount(datasetname)\n",
    "    sizemult = gettypemult(datasetname)    \n",
    "\n",
    "    return base * sizemult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foreachfileindir(dir, do):\n",
    "    for filename in os.scandir(dir):\n",
    "        if filename.is_file():\n",
    "            do(filename)\n",
    "\n",
    "def readlinestointarr(filename, mult = None):\n",
    "    arr = []\n",
    "    with open(filename) as f:\n",
    "        for l in f:\n",
    "            if mult != None:\n",
    "                arr.append(int(float(l)*mult))\n",
    "            else:\n",
    "                arr.append(int(l))\n",
    "    return arr\n",
    "\n",
    "analysis_def = [\"avg\", \"std\", \"max\", \"min\"]\n",
    "def analyse(data):\n",
    "    avg = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    _max = np.max(data)\n",
    "    _min = np.min(data)\n",
    "    return (avg, std, _max, _min, len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbuilddirinfo(dir, mult = None):\n",
    "    basedata = {}\n",
    "    analysisdata = {}\n",
    "    def addfilecontent(fn):\n",
    "        newname = str(fn.name).replace(\"_hprtree\", \"\").replace(\"_rstar\", \"\")\n",
    "        basedata[newname] = readlinestointarr(fn, mult)\n",
    "    foreachfileindir(dir, addfilecontent)\n",
    "    for (k, v) in basedata.items():\n",
    "        analysisdata[k] = analyse(v)\n",
    "    return (basedata, analysisdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_plotdirinfos = True\n",
    "\n",
    "def plotdirinfos(datahpr, datarst, title, fname, ylabel = \"\", subdir = \"\"):\n",
    "    labels = []\n",
    "    plt.figure()\n",
    "    # start_plot0 = time.perf_counter()\n",
    "    parts = plt.violinplot(datahpr, showmeans=False, showmedians=False, showextrema=False)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(hprcol)\n",
    "        # pc.set_edgecolor('black')\n",
    "        pc.set_alpha(1)\n",
    "    color = parts[\"bodies\"][0].get_facecolor().flatten()\n",
    "    labels.append((mpatches.Patch(color=color), hprlab))\n",
    "    # end_plot0 = time.perf_counter()\n",
    "    # print(f\"plot0 done in {end_plot0 - start_plot0}\")\n",
    "\n",
    "    # start_plot1 = time.perf_counter()\n",
    "    parts = plt.violinplot(datarst, showmeans=False, showmedians=False, showextrema=False)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor(rstcol)\n",
    "        # pc.set_edgecolor('black')\n",
    "        pc.set_alpha(1)\n",
    "    color = parts[\"bodies\"][0].get_facecolor().flatten()\n",
    "    labels.append((mpatches.Patch(color=color), rstlab))\n",
    "    # end_plot1 = time.perf_counter()\n",
    "    # print(f\"plot1 done in {end_plot0 - start_plot0}\")\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.legend(*zip(*labels), loc=2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(f\"{title}\")\n",
    "\n",
    "    # start_save = time.perf_counter()\n",
    "    if save_plotdirinfos:\n",
    "        plt.savefig(f\"{outdir}{subdir}{fname}{imgext}\")\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    # end_save = time.perf_counter()\n",
    "    # print(f\"save done in {end_plot0 - start_plot0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_print = False\n",
    "\n",
    "def printinit():\n",
    "    global writetext\n",
    "    writetext = \"\"\n",
    "\n",
    "def printcommit(filename):\n",
    "    writefile = open(filename, \"w+\")\n",
    "    writefile.write(writetext)\n",
    "    writefile.close()\n",
    "    writefile = None\n",
    "def print_or_write(text):\n",
    "    if do_print:\n",
    "        print(text)\n",
    "    else:\n",
    "        global writetext\n",
    "        writetext += text\n",
    "        writetext += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_analytics(func_hprdict, func_rstdict, func_hpranal, func_rstanal, subdir, statname, newnamefunc, envelopes = False):\n",
    "    func_hprarr = {}\n",
    "    func_rstarr = {}\n",
    "    func_mindiff = 999e999\n",
    "    func_mindiff_name = None\n",
    "    func_maxdiff = -999e999\n",
    "    func_maxdiff_name = None\n",
    "    func_worsecount = 0\n",
    "    func_bettercount = 0\n",
    "\n",
    "    printinit()\n",
    "\n",
    "    for sz in env_sizes:\n",
    "        szstr = str(sz)\n",
    "        for mult in types.values():\n",
    "            multstr = str(mult)\n",
    "            for ridx in range(len(ranges)):\n",
    "                ridxstr = str(ridx)\n",
    "                idxstr = szstr + '_' + multstr + '_' + ridxstr\n",
    "                func_hprarr[idxstr] = []\n",
    "                func_rstarr[idxstr] = []\n",
    "\n",
    "    for k, v in func_hprdict.items():\n",
    "        [name, env_size] = k.rsplit(\".\", 1)\n",
    "        newname = newnamefunc(name)\n",
    "        count = getcount(newname)\n",
    "        szstr = str(env_size)\n",
    "        typemult = gettypemult(newname)\n",
    "        multstr = str(typemult)\n",
    "        typen = typename_by_mult(typemult)\n",
    "        ridx = rangeindex(count)\n",
    "        ridxstr = str(ridx)\n",
    "        idxstr = szstr + '_' + multstr + '_' + ridxstr\n",
    "\n",
    "        func_hprarr[idxstr].append(v)\n",
    "        func_rstarr[idxstr].append(func_rstdict.get(k, [0]))\n",
    "\n",
    "        print_or_write(f\"{newname} ({idxstr}) {{{env_size}}}\")\n",
    "        hpranal = func_hpranal[k]\n",
    "        print_or_write(f\"hpranal: {hpranal}\")\n",
    "        if too_big_for_rstar.count(newname) == 1:\n",
    "            print_or_write(\"rstanal: dead\")\n",
    "            print_or_write(\"better (inf)\\n\")\n",
    "            func_bettercount += 1\n",
    "        else:\n",
    "            rstanal = func_rstanal[k]\n",
    "            print_or_write(f\"rstanal: {rstanal}\")\n",
    "            mult = rstanal[0]/hpranal[0]\n",
    "            if mult < 1:\n",
    "                print_or_write(f\"worse ({mult})\\n\")\n",
    "                func_worsecount += 1\n",
    "            else:\n",
    "                print_or_write(f\"better ({mult})\\n\")\n",
    "                func_bettercount += 1\n",
    "            if mult > func_maxdiff:\n",
    "                func_maxdiff = mult\n",
    "                func_maxdiff_name = f\"{newname} ({idxstr}) {{{env_size}}}\"\n",
    "            if mult < func_mindiff:\n",
    "                func_mindiff = mult\n",
    "                func_mindiff_name = f\"{newname} ({idxstr}) {{{env_size}}}\"\n",
    "\n",
    "\n",
    "    print_or_write(f\"mindiff: {func_mindiff} [{func_mindiff_name}]\\nmaxdiff: {func_maxdiff}  [{func_maxdiff_name}]\")\n",
    "    print_or_write(f\"hpr is worse (in average) in {func_worsecount} datasets\")\n",
    "    print_or_write(f\"and better (in average) in {func_bettercount} datasets\")\n",
    "    printcommit(f\"{outdir}{subdir}{statname}.txt\")\n",
    "    return (func_hprarr, func_rstarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildsubdir = \"build/\"\n",
    "builddir = basedir + buildsubdir\n",
    "ensure_exists(f\"{outdir}{buildsubdir}\")\n",
    "\n",
    "buildhprdir = builddir + \"hprtree/\"\n",
    "buildrstdir = builddir + \"rstar/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "(build_hprdict, build_hpranal) = getbuilddirinfo(buildhprdir, 0.000001)\n",
    "(build_rstdict, build_rstanal) = getbuilddirinfo(buildrstdir, 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_hprarr = {}\n",
    "build_rstarr = {}\n",
    "build_mindiff = 999e999\n",
    "build_mindiff_name = None\n",
    "build_maxdiff = -999e999\n",
    "build_maxdiff_name = None\n",
    "build_worsecount = 0\n",
    "build_bettercount = 0\n",
    "\n",
    "printinit()\n",
    "for (typen, typesz) in types.items():\n",
    "    for previous, current in zip(sizes, sizes[1:]):\n",
    "        key = f\"{typen}_{previous}_{current}\"\n",
    "        build_hprarr[key] = []\n",
    "        build_rstarr[key] = []\n",
    "        for k, v in build_hprdict.items():\n",
    "            newname = k.replace(\"bench_build_\", \"\")\n",
    "            count = getcount(newname)\n",
    "            if count > previous and count <= current and gettypemult(newname) == typesz:\n",
    "                build_hprarr[key].append(v)\n",
    "                build_rstarr[key].append(build_rstdict.get(k, [0]))\n",
    "                print_or_write(f\"{newname} ({key})\")\n",
    "                hpranal = build_hpranal[k]\n",
    "                print_or_write(f\"hpranal: {hpranal}\")\n",
    "                if too_big_for_rstar.count(newname) == 1:\n",
    "                    print_or_write(\"rstanal: dead\")\n",
    "                    print_or_write(\"better (inf)\\n\")\n",
    "                else:\n",
    "                    rstanal = build_rstanal[k]\n",
    "                    print_or_write(f\"rstanal: {rstanal}\")\n",
    "                    mult = rstanal[0]/hpranal[0]\n",
    "                    if mult < 1:\n",
    "                        print_or_write(f\"worse ({mult})\\n\")\n",
    "                        build_worsecount += 1\n",
    "                    else:\n",
    "                        print_or_write(f\"better ({mult})\\n\")\n",
    "                        build_bettercount += 1\n",
    "                    if mult > build_maxdiff:\n",
    "                        build_maxdiff = mult\n",
    "                        build_maxdiff_name = f\"{newname} ({key})\"\n",
    "                    if mult < build_mindiff:\n",
    "                        build_mindiff = mult\n",
    "                        build_mindiff_name = f\"{newname} ({key})\"\n",
    "        plotdirinfos(build_hprarr[key], build_rstarr[key], f\"Build times with elements of {typesz} bytes\", key, \"Build time in ms\", buildsubdir)\n",
    "print_or_write(f\"mindiff: {build_mindiff} [{build_mindiff_name}]\\nmaxdiff: {build_maxdiff}  [{build_maxdiff_name}]\")\n",
    "print_or_write(f\"hpr is worse (in average) in {build_worsecount} datasets\")\n",
    "print_or_write(f\"and better (in average) in {build_bettercount} datasets\")\n",
    "printcommit(f\"{outdir}{buildsubdir}buildstats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delbuilddir = basedir + \"build/\"\n",
    "delsubdir = \"delete/\"\n",
    "ensure_exists(f\"{outdir}{delsubdir}\")\n",
    "\n",
    "delhprdir = delbuilddir + \"d_hprtree/\"\n",
    "delrstdir = delbuilddir + \"d_rstar/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(delete_hprdict, delete_hpranal) = getbuilddirinfo(delhprdir, 0.001)\n",
    "(delete_rstdict, delete_rstanal) = getbuilddirinfo(delrstdir, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_hprarr = {}\n",
    "del_rstarr = {}\n",
    "del_mindiff = 999e999\n",
    "del_mindiff_name = None\n",
    "del_maxdiff = -999e999\n",
    "del_maxdiff_name = None\n",
    "del_worsecount = 0\n",
    "del_bettercount = 0\n",
    "\n",
    "del_aggregation = {}\n",
    "\n",
    "printinit()\n",
    "for (typen, typesz) in types.items():\n",
    "    for previous, current in zip(sizes, sizes[1:]):\n",
    "        key = f\"{typen}_{previous}_{current}\"\n",
    "        del_hprarr[key] = []\n",
    "        del_rstarr[key] = []\n",
    "        for k, v in delete_hprdict.items():\n",
    "            newname = k.replace(\"bench_build_\", \"\")\n",
    "            count = getcount(newname)\n",
    "            if count > previous and count <= current and gettypemult(newname) == typesz:\n",
    "                del_hprarr[key].append(v)\n",
    "                del_rstarr[key].append(delete_rstdict.get(k, [0]))\n",
    "                print_or_write(f\"{newname} ({key})\")\n",
    "                hpranal = delete_hpranal[k]\n",
    "                print_or_write(f\"hpranal: {hpranal}\")\n",
    "                if too_big_for_rstar.count(newname) == 1:\n",
    "                    print_or_write(\"rstanal: dead\")\n",
    "                    print_or_write(\"better (inf)\\n\")\n",
    "                else:\n",
    "                    rstanal = delete_rstanal[k]\n",
    "                    print_or_write(f\"rstanal: {rstanal}\")\n",
    "                    mult = rstanal[0]/hpranal[0]\n",
    "                    if mult < 1:\n",
    "                        print_or_write(f\"worse ({mult})\\n\")\n",
    "                        del_worsecount += 1\n",
    "                    else:\n",
    "                        print_or_write(f\"better ({mult})\\n\")\n",
    "                        del_bettercount += 1\n",
    "                    if mult > del_maxdiff:\n",
    "                        del_maxdiff = mult\n",
    "                        del_maxdiff_name = f\"{newname} ({key})\"\n",
    "                    if mult < del_mindiff:\n",
    "                        del_mindiff = mult\n",
    "                        del_mindiff_name = f\"{newname} ({key})\"\n",
    "                    rngidx = rangeindex(count)\n",
    "                    (temp_min, temp_max) = del_aggregation.get(rngidx, (999e999, -999e999))\n",
    "                    if mult < temp_min:\n",
    "                        temp_min = mult\n",
    "                    if mult > temp_max:\n",
    "                        temp_max = mult\n",
    "                    del_aggregation[rngidx] = (temp_min, temp_max)\n",
    "        plotdirinfos(del_hprarr[key], del_rstarr[key], f\"Deletion times with elements of {typesz} bytes\", key, \"Deletion time in us\", delsubdir)\n",
    "print_or_write(f\"mindiff: {del_mindiff} [{del_mindiff_name}]\\nmaxdiff: {del_maxdiff}  [{del_maxdiff_name}]\")\n",
    "print_or_write(f\"hpr is worse (in average) in {del_worsecount} datasets\")\n",
    "print_or_write(f\"and better (in average) in {del_bettercount} datasets\\n\")\n",
    "print_or_write(f\"aggregation per range: {del_aggregation}\")\n",
    "printcommit(f\"{outdir}{delsubdir}deletestats.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "qallsubdir = \"queryall/\"\n",
    "qallbuilddir = basedir + qallsubdir\n",
    "ensure_exists(f\"{outdir}{qallsubdir}\")\n",
    "\n",
    "qallhprdir = qallbuilddir + \"/hprtree\"\n",
    "qallrstdir = qallbuilddir + \"/rstar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "(qall_hprdict, qall_hpranal) = getbuilddirinfo(qallhprdir, 0.001)\n",
    "(qall_rstdict, qall_rstanal) = getbuilddirinfo(qallrstdir, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "qall_hprarr = {}\n",
    "qall_rstarr = {}\n",
    "qall_mindiff = 999e999\n",
    "qall_mindiff_name = None\n",
    "qall_maxdiff = -999e999\n",
    "qall_maxdiff_name = None\n",
    "qall_worsecount = 0\n",
    "qall_bettercount = 0\n",
    "\n",
    "printinit()\n",
    "for (typen, typesz) in types.items():\n",
    "    for previous, current in zip(sizes, sizes[1:]):\n",
    "        key = f\"{typen}_{previous}_{current}\"\n",
    "        qall_hprarr[key] = []\n",
    "        qall_rstarr[key] = []\n",
    "        for k, v in qall_hprdict.items():\n",
    "            newname = k.replace(\"bench_queryall_\", \"\")\n",
    "            count = getcount(newname)\n",
    "            if count > previous and count <= current and gettypemult(newname) == typesz:\n",
    "                qall_hprarr[key].append(v)\n",
    "                qall_rstarr[key].append(qall_rstdict.get(k, [0]))\n",
    "                print_or_write(f\"{newname} ({key})\")\n",
    "                hpranal = qall_hpranal[k]\n",
    "                print_or_write(f\"hpranal: {hpranal}\")\n",
    "                if too_big_for_rstar.count(newname) == 1:\n",
    "                    print_or_write(\"rstanal: dead\")\n",
    "                    print_or_write(\"better (inf)\\n\")\n",
    "                else:\n",
    "                    rstanal = qall_rstanal[k]\n",
    "                    print_or_write(f\"rstanal: {rstanal}\")\n",
    "                    mult = rstanal[0]/hpranal[0]\n",
    "                    if mult < 1:\n",
    "                        print_or_write(f\"worse ({mult})\\n\")\n",
    "                        qall_worsecount += 1\n",
    "                    else:\n",
    "                        print_or_write(f\"better ({mult})\\n\")\n",
    "                        qall_bettercount += 1\n",
    "                    if mult > qall_maxdiff:\n",
    "                        qall_maxdiff = mult\n",
    "                        qall_maxdiff_name = f\"{newname} ({key})\"\n",
    "                    if mult < qall_mindiff:\n",
    "                        qall_mindiff = mult\n",
    "                        qall_mindiff_name = f\"{newname} ({key})\"\n",
    "        plotdirinfos(qall_hprarr[key], qall_rstarr[key], f\"Query times for all elements of {typesz} bytes\", key, \"Query time in us\", qallsubdir)\n",
    "print_or_write(f\"mindiff: {qall_mindiff} [{qall_mindiff_name}]\\nmaxdiff: {qall_maxdiff}  [{qall_maxdiff_name}]\")\n",
    "print_or_write(f\"hpr is worse (in average) in {qall_worsecount} datasets\")\n",
    "print_or_write(f\"and better (in average) in {qall_bettercount} datasets\")\n",
    "printcommit(f\"{outdir}{qallsubdir}qallstats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpresubdir = \"querypre/\"\n",
    "qprebuilddir = basedir + qpresubdir\n",
    "ensure_exists(f\"{outdir}{qpresubdir}\")\n",
    "\n",
    "qprehprdir = qprebuilddir + \"hprtree/\"\n",
    "qprerstdir = qprebuilddir + \"rstar/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "(qpre_hprdict, qpre_hpranal) = getbuilddirinfo(qprehprdir, 0.001)\n",
    "(qpre_rstdict, qpre_rstanal) = getbuilddirinfo(qprerstdir, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "(qpre_hprarr, qpre_rstarr) = do_analytics(qpre_hprdict, qpre_rstdict, qpre_hpranal, qpre_rstanal, qpresubdir, \"qprestats\", lambda e:e.replace(\"ordered_\", \"synthetic_180x90x\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sz in env_sizes:\n",
    "    szstr = str(sz)\n",
    "    for mult in types.values():\n",
    "        multstr = str(mult)\n",
    "        for ridx in range(len(ranges)):\n",
    "            ridxstr = str(ridx)\n",
    "            idxstr = szstr + '_' + multstr + '_' + ridxstr\n",
    "            (c, n) = ranges[ridx]\n",
    "            if len(qpre_hprarr[idxstr]) != 0 and len(qpre_rstarr[idxstr]) != 0:\n",
    "                plotdirinfos(qpre_hprarr[idxstr], qpre_rstarr[idxstr], f\"Query time for envelopes containing {szstr} elements\\nwith a size of {mult} bytes and an index size\\nbetween {c} and {n} elements\", f\"{typename_by_mult(mult)}_{c}_{n}-{szstr}\", \"Query time in us\", qpresubdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size_files\n",
    "sizesubdir = \"size/\"\n",
    "szfiledir = basedir + \"/szfiles\"\n",
    "ensure_exists(f\"{outdir}{sizesubdir}\")\n",
    "\n",
    "sizes_hprtree = {}\n",
    "with open(szfiledir + \"/hprtree\") as f:\n",
    "    for l in f:\n",
    "        (k, v) = l.split(\": \")\n",
    "        sizes_hprtree[k[20:]] = int(v)\n",
    "sizes_rstar = {}\n",
    "with open(szfiledir + \"/rstar\") as f:\n",
    "    for l in f:\n",
    "        (k, v) = l.split(\": \")\n",
    "        sizes_rstar[k[18:]] = int(v)\n",
    "\n",
    "for k, v in sizes_hprtree.items():\n",
    "    ret = sizes_rstar.get(k)\n",
    "    if too_big_for_rstar.count(k) != 1:\n",
    "        assert ret != None, f\"rstar doesn't have {k}\"\n",
    "        assert v < ret\n",
    "for k, v in sizes_rstar.items():\n",
    "    ret = sizes_hprtree.get(k)\n",
    "    assert ret != None, f\"hprtree doesn't have {k}\"\n",
    "    assert v > ret\n",
    "\n",
    "data_size = []\n",
    "for k, v in sizes_hprtree.items():\n",
    "    data_size.append((v, theoreticalmin(k), sizes_rstar.get(k, -1)))\n",
    "\n",
    "for (hpr_sz, min_sz, rst_sz) in data_size:\n",
    "    if rst_sz != -1:\n",
    "        assert min_sz < hpr_sz and hpr_sz < rst_sz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size.sort(key=lambda e:e[0])\n",
    "data_hprtree, data_min, data_rstar = zip(*data_size)\n",
    "\n",
    "data_hpr_diff = [max(a / b, 0)*100 for a, b in zip(data_hprtree, data_min)]\n",
    "data_rst_diff = [max(a / b, 0)*100 for a, b in zip(data_rstar, data_min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_comb_size = True\n",
    "\n",
    "def size_multi_plot(start, end, title):\n",
    "    plt.figure()\n",
    "    \n",
    "    prev_end = start[0]\n",
    "\n",
    "    for (s, e) in zip(start, end):\n",
    "        l = e - s\n",
    "        x = [*range(prev_end, prev_end+l)]\n",
    "        prev_end += l\n",
    "        plt.scatter(x, data_hpr_diff[s:e], marker=\"_\", linewidths=0.5, color=\"green\", label=hprlab)\n",
    "        plt.scatter(x, data_rst_diff[s:e], marker=\"_\", linewidths=0.5, color=\"orange\", label=rstlab)\n",
    "\n",
    "    l, r = plt.xlim()\n",
    "    plt.hlines([100], [l], [r], linewidth=0.5, alpha=0.5, colors=[\"purple\"], label=\"Theoretical minimum\")\n",
    "    plt.ylabel(\"Size in memory in % of theoretical minimum\")\n",
    "    h,l = plt.gca().get_legend_handles_labels()\n",
    "    plt.legend([*h[:2], h[-1]], [*l[:2], l[-1]], loc=6)\n",
    "\n",
    "    # plt.title(f\"size_{start}_{end}\")\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.xticks([])\n",
    "    if save_comb_size:\n",
    "        _, top = plt.ylim()\n",
    "        plt.savefig(f\"{outdir}{sizesubdir}sizegrp_{top}{imgext}\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "size_multi_plot([0, 38, 57, 114, 172, 285, 456, 475, 532], [19, 57, 76, 133, 190, 304, 475, 494, 551], \"\") # 150 - 450\n",
    "\n",
    "size_multi_plot([19, 76, 152, 210, 342, 494], [38, 114, 171, 228, 361, 513], \"\") # 140 - 230\n",
    "\n",
    "size_multi_plot([133, 190, 228, 247, 266, 304, 323, 361, 380, 399, 419, 437, 514, 551, 571, 589, 608, 627, 647, 666, 684, 704, 722, 742], [152, 209, 247, 266, 285, 323, 342, 380, 399, 418, 437, 456, 532, 570, 589, 608, 627, 646, 665, 684, 703, 722, 741, 760], \"\") # 100 - 140\n",
    "\n",
    "size_multi_plot([418, 513, 570, 209, 171], [419, 514, 571, 210, 172], \"\") # 1600 - 6500\n",
    "\n",
    "size_multi_plot([646, 665, 703, 741], [647, 666, 704, 742], \"\") # 0 - 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size.sort(key=lambda e:e[1])\n",
    "data_hprtree, data_min, data_rstar = zip(*data_size)\n",
    "\n",
    "data_hpr_diff = [max(a / b, 0)*100 for a, b in zip(data_hprtree, data_min)]\n",
    "data_rst_diff = [max(a / b, 0)*100 for a, b in zip(data_rstar, data_min)]\n",
    "\n",
    "save_all_size = True\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "sz = len(data_min)\n",
    "x = [*range(sz)]\n",
    "plt.scatter(x, data_hpr_diff, marker=\"_\", linewidths=0.5, color=\"green\", label=hprlab)\n",
    "plt.scatter(x, data_rst_diff, marker=\"_\", linewidths=0.5, color=\"orange\", label=rstlab)\n",
    "l, r = plt.xlim()\n",
    "plt.hlines([100], [l], [r], linewidth=0.5, alpha=0.5, colors=[\"purple\"], label=\"Theoretical minimum\")\n",
    "plt.ylabel(\"Size in memory in percent of theoretical minimum\")\n",
    "plt.legend()\n",
    "plt.xticks([])\n",
    "if save_all_size:\n",
    "    plt.savefig(f\"{outdir}{sizesubdir}size_all_p100{imgext}\")\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.title(f\"size_all_p100\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min_kib = [ sz / 1024 for sz in data_min]\n",
    "data_hprtree_kib = [ sz / 1024 for sz in data_hprtree]\n",
    "data_rstar_kib = [ sz / 1024 for sz in data_rstar]\n",
    "\n",
    "plt.figure(clear=True)\n",
    "x = [*range(len(data_min_kib))]\n",
    "plt.scatter(x, data_hprtree_kib, marker=\"_\", linewidths=0.5, color=\"green\", label=\"HPRTree\")\n",
    "plt.scatter(x, data_rstar_kib, marker=\"_\", linewidths=0.5, color=\"orange\", label=\"R*Tree\")\n",
    "plt.plot(data_min_kib, linewidth=0.5, alpha=0.5, color=\"purple\", label=\"Theoretical minimum\")\n",
    "plt.ylabel(\"Size in memory in kibibytes\")\n",
    "plt.legend()\n",
    "plt.xticks([])\n",
    "if save_all_size:\n",
    "    plt.savefig(f\"{outdir}{sizesubdir}size_all_bytes{imgext}\")\n",
    "    plt.close()\n",
    "else:\n",
    "    plt.title(f\"size_all_bytes\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# size_plot(0, 19)# size_plot(19, 38)# size_plot(38, 57)# size_plot(57, 76)# size_plot(76, 114)# size_plot(114, 133)# size_plot(133, 152)# size_plot(152, 171)# size_plot(171, 172)# size_plot(172, 190)# size_plot(190, 209)# size_plot(209, 210)# size_plot(210, 228)# size_plot(228, 247)# size_plot(247, 266)# size_plot(266, 285)# size_plot(285, 304)# size_plot(304, 323)# size_plot(323, 342)# size_plot(342, 361)# size_plot(361, 380)# size_plot(380, 399)# size_plot(399, 418)# size_plot(418, 419)# size_plot(419, 437)# size_plot(437, 456)# size_plot(456, 475)# size_plot(475, 494)# size_plot(494, 513)# size_plot(513, 514)# size_plot(514, 532)# size_plot(532, 551)# size_plot(551, 570)# size_plot(570, 571)# size_plot(571, 589)# size_plot(589, 608)# size_plot(608, 627)# size_plot(627, 646)# size_plot(646, 647)# size_plot(647, 665)# size_plot(665, 666)# size_plot(666, 684)# size_plot(684, 703)# size_plot(703, 704)# size_plot(704, 722)# size_plot(722, 741)# size_plot(741, 742)# size_plot(742, 760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hprtree = 999e999\n",
    "best_rsttree = 999e999\n",
    "worst_hprtree = -999e999\n",
    "worst_rsttree = -999e999\n",
    "\n",
    "for (d_hpr, d_rst) in zip(data_hpr_diff, data_rst_diff):\n",
    "    if best_hprtree > d_hpr:\n",
    "        best_hprtree = d_hpr\n",
    "    if worst_hprtree < d_hpr:\n",
    "        worst_hprtree = d_hpr\n",
    "    if d_rst != 0:\n",
    "        if best_rsttree > d_rst:\n",
    "            best_rsttree = d_rst\n",
    "        if worst_rsttree < d_rst:\n",
    "            worst_rsttree = d_rst\n",
    "\n",
    "best_comp = 999e999\n",
    "worst_comp = -999e999\n",
    "\n",
    "for (d_hpr, d_rst) in zip(data_hprtree, data_rstar):\n",
    "    if d_rst != -1:\n",
    "        comp = d_hpr / d_rst\n",
    "        if comp < best_comp:\n",
    "            best_comp = comp\n",
    "        if comp > worst_comp:\n",
    "            worst_comp = comp\n",
    "\n",
    "printinit()\n",
    "print_or_write(f\"best_hprtree: {best_hprtree}\\nworst_hprtree: {worst_hprtree}\\n\\nbest_rsttree: {best_rsttree}\\nworst_rsttree: {worst_rsttree}\\n\")\n",
    "print_or_write(f\"best_comp: {best_comp}\\nworst_comp: {worst_comp}\")\n",
    "printcommit(f\"{outdir}{sizesubdir}sizestats.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot(data, mean, std, ylabel, lineon=None):\n",
    "#     plt.figure()\n",
    "#     plt.scatter(range(len(data)), data, marker=\".\", s=0.8)\n",
    "#     # plt.plot(data)\n",
    "#     plt.ylabel(ylabel)\n",
    "#     plt.xlabel(\"N=\" + str(len(data)))\n",
    "#     if lineon != None:\n",
    "#         for line in lineon:\n",
    "#             plt.axhline(\n",
    "#                 line[0], color=line[1], linewidth=0.9, ls=(0, (1, 5))\n",
    "#             ).set_label(line[2])\n",
    "#     plt.axhline(mean, color=\"red\", linewidth=0.7, ls=\"--\").set_label(\"mean\")\n",
    "#     plt.axhline(mean + std, color=\"purple\", linewidth=0.7).set_label(\n",
    "#         \"mean±standard deviation\"\n",
    "#     )\n",
    "#     plt.axhline(mean - std, color=\"purple\", linewidth=0.7)\n",
    "#     plt.axhspan(mean + std, mean - std, facecolor=\"purple\", alpha=0.1)\n",
    "#     plt.xticks([])\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# def plot_sorted(data, mean, std, ylabel, lineon=None):\n",
    "#     plt.figure()\n",
    "#     plt.plot(data.sort_values(by=[data.columns[0]], ascending=True, ignore_index=True))\n",
    "#     plt.ylabel(ylabel)\n",
    "#     plt.xlabel(\"CDF\\nN=\" + str(len(data)))\n",
    "#     if lineon != None:\n",
    "#         for line in lineon:\n",
    "#             plt.axhline(\n",
    "#                 line[0], color=line[1], linewidth=0.9, ls=(0, (1, 5))\n",
    "#             ).set_label(line[2])\n",
    "#     plt.axhline(mean, color=\"red\", linewidth=0.7, ls=\"--\").set_label(\"mean\")\n",
    "#     plt.axhline(mean + std, color=\"purple\", linewidth=0.7).set_label(\n",
    "#         \"mean±standard deviation\"\n",
    "#     )\n",
    "#     plt.axhline(mean - std, color=\"purple\", linewidth=0.7)\n",
    "#     plt.axhspan(mean + std, mean - std, facecolor=\"purple\", alpha=0.1)\n",
    "#     plt.xticks(\n",
    "#         [0, len(data) / 4, len(data) / 2, len(data) / (4 / 3), len(data)],\n",
    "#         [\"0.0\", \"0.25\", \"0.5\", \"0.75\", \"1.0\"],\n",
    "#     )\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_timings_ns = pd.read_csv('../stats/detect_timings.txt')\n",
    "# copy_timings_ns = pd.read_csv('../stats/copy_timings.txt')\n",
    "# startup_timings_ns = pd.read_csv('../stats/startup_timings.txt')\n",
    "# crop_timings_ns = pd.read_csv('../stats/crop_timings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect_timings_us = detect_timings_ns / 1000\n",
    "# detect_timings_ms = detect_timings_us / 1000\n",
    "# detect_timings_mean = detect_timings_ms.mean()[0]\n",
    "# print(\"detect_timings_mean: \" + str(detect_timings_mean))\n",
    "# detect_timings_std = detect_timings_ms.std()[0]\n",
    "# print(\"detect_timings_std: \" + str(detect_timings_std))\n",
    "# print(\"min: \" + str(detect_timings_ms.min()[0]))\n",
    "# print(\"max: \" + str(detect_timings_ms.max()[0]))\n",
    "# print(\"N: \" + str(len(detect_timings_ns)))\n",
    "\n",
    "# print(\"\\n\")\n",
    "\n",
    "# copy_timings_us = copy_timings_ns / 1000\n",
    "# copy_timings_mean = copy_timings_us.mean()[0]\n",
    "# print(\"copy_timings_mean: \" + str(copy_timings_mean))\n",
    "# copy_timings_std = copy_timings_us.std()[0]\n",
    "# print(\"copy_timings_std: \" + str(copy_timings_std))\n",
    "# print(\"min: \" + str(copy_timings_us.min()[0]))\n",
    "# print(\"max: \" + str(copy_timings_us.max()[0]))\n",
    "# print(\"N: \" + str(len(copy_timings_ns)))\n",
    "\n",
    "# print(\"\\n\")\n",
    "\n",
    "# startup_timings_us = startup_timings_ns / 1000\n",
    "# startup_timings_ms = startup_timings_us / 1000\n",
    "# startup_timings_mean = startup_timings_ms.mean()[0]\n",
    "# print(\"startup_timings_mean: \" + str(startup_timings_mean))\n",
    "# startup_timings_std = startup_timings_ms.std()[0]\n",
    "# print(\"startup_timings_std: \" + str(startup_timings_std))\n",
    "# print(\"min: \" + str(startup_timings_ms.min()[0]))\n",
    "# print(\"max: \" + str(startup_timings_ms.max()[0]))\n",
    "# print(\"N: \" + str(len(startup_timings_ns)))\n",
    "\n",
    "# print(\"\\n\")\n",
    "\n",
    "# crop_timings_us = crop_timings_ns / 1000\n",
    "# crop_timings_ms = crop_timings_us / 1000\n",
    "# crop_timings_mean = crop_timings_ms.mean()[0]\n",
    "# print(\"crop_timings_mean: \" + str(crop_timings_mean))\n",
    "# crop_timings_std = crop_timings_ms.std()[0]\n",
    "# print(\"crop_timings_std: \" + str(crop_timings_std))\n",
    "# print(\"min: \" + str(crop_timings_ms.min()[0]))\n",
    "# print(\"max: \" + str(crop_timings_ms.max()[0]))\n",
    "# print(\"N: \" + str(len(crop_timings_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(detect_timings_ms, detect_timings_mean, detect_timings_std, 'Detection timings in ms')\n",
    "# plot_sorted(detect_timings_ms, detect_timings_mean, detect_timings_std, 'Detection timings in ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(copy_timings_us, copy_timings_mean, copy_timings_std, 'Copy timings in us')\n",
    "# plot_sorted(copy_timings_us, copy_timings_mean, copy_timings_std, 'Copy timings in us')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(startup_timings_ms, startup_timings_mean, startup_timings_std, 'Startup timings in ms')\n",
    "# plot_sorted(startup_timings_ms, startup_timings_mean, startup_timings_std, 'Startup timings in ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(crop_timings_ms, crop_timings_mean, crop_timings_std, 'Crop timings in ms', [[16.666, 'green', '60FPS capable'], [33.333, 'orange', '30FPS capable']])\n",
    "# plot_sorted(crop_timings_ms, crop_timings_mean, crop_timings_std, 'Crop timings in ms', [[16.666, 'green', '60FPS capable'], [33.333, 'orange', '30FPS capable']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
